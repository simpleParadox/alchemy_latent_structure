program: src/models/train.py
method: grid
metric:
  goal: minimize
  name: val_loss
parameters:
  # Sweep parameter - model size variations
  model_size:
    values: ['xsmall']
    # values: ['small', 'medium']
  # Fixed parameters from job.sh
  train_data_path:
    value: '/home/rsaha/projects/dm_alchemy/src/data/generated_data/decompositional_chemistry_samples_167424_80_unique_stones_train_shop_3_qhop_1.json'
  val_data_path:
    value: '/home/rsaha/projects/dm_alchemy/src/data/generated_data/decompositional_chemistry_samples_167424_80_unique_stones_val_shop_3_qhop_1.json'
  task_type:
    value: 'classification'
  epochs:
    value: 60
  batch_size:
    value: 256
  num_workers:
    value: 13
  wandb_mode:
    value: 'online'  # Changed from offline to online for sweep tracking
  weight_decay:
    value: 0.01
  
  # Default values for other parameters (from train.py defaults)
  # val_split:
  #   value: null
  val_split_seed:
    values: [0,1,2]
  max_seq_len:
    value: 2048
  learning_rate:
    value: 0.0001
  seed:
    value: 42
  filter_query_from_support:
    value: true # if qhop=shop length.
  wandb_project:
    value: 'alchemy-meta-learning'
  # wandb_entity:
  #   value: null
  log_interval:
    value: 50

# Command to run with accelerate
command:
  - ${env}
  - accelerate
  - launch
  - --multi_gpu
  - --gpu_ids=all
  - --main_process_port=0
  - ${program}
  - ${args}
